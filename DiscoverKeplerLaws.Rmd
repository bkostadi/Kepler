---
title: "Data Science Lessons Inspired by Kepler's Laws"
subtitle: "An MAA Book Chapter"
author: Boyan Kostadinov^[Mathematics Department, bkostadinov@citytech.cuny.edu]
date: "New York City College of Technology, CUNY"
output: 
  bookdown::pdf_document2:
    toc: true
    citation_package: biblatex
    fig_caption: yes
header-includes: 
  - \usepackage{hyperref}
link-citations: yes
bibliography: bk-references.bib
---


```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(fig.align='center', fig.width=6, fig.height=3)
library(tidyverse) # Tidyverse collection
library(broom) # for tidy()
library(knitr) # for kable()
library(kableExtra)
library(mosaic)
library(mosaicCalc)
```


# Computing Framework

We scaffold the projects by presenting step-by-step the mathematical ideas, along with the computational techniques needed for the students to work through all activities. We use the \textsf{R} programming language \cite{chambers} for all computations and visualizations. We recommend using RStudio \cite{allaire2021}, either locally installed, or RStudio Cloud \cite{allaire2022}. Prior programming experience in \textsf{R} is not required, but in this case the students are expected to learn the basics of \textsf{R} and R Markdown. RStudio supports R Markdown (or the new generation Quarto) notebooks, which allows one to unify plain text narrative, mathematical expressions in \LaTeX\, and \textsf{R} code (or Python via the `reticulate` R package), and create fully reproducible, publication quality project reports and presentations. 

We recommend the following resources to learn the basics of \textsf{R}: \cite{braun2021, cornelissen2022}, and R Markdown: \cite{RMarkdown,grolemund2021,xie2022}. We use the `mosaic`, `mosaicCalc` and `ggformula` R packages, developed by Project MOSAIC, designed to facilitate the use of \textsf{R} in statistics and calculus instruction, \cite{pruim2017,kaplan2020,kaplan2021}. We also use the `tidyverse` \cite{wickham2019,wickham2021b} collection of packages developed by RStudio, and specifically `ggplot2` \cite{wickham2021a} for visualizations, and `dplyr` \cite{wickham2021} for data analysis. The reader can find additional resources on computational-problem solving with \textsf{R} in \cite{kaplan2015, benakli2017, kostadinov2019}.

We have implemented all computations and visualizations in this chapter using \textsf{R} in an R Markdown notebook (Rmd), which can be downloaded from GitHub \cite{kostadinov2022}. The Rmd notebook can be run in RStudio, which is freely available for Windows, Mac, and Linux:

-   \textsf{R} installers: \url{https://cloud.r-project.org/}
-   RStudio installers: \url{https://www.rstudio.com/products/rstudio/download/}

A cloud-based option (free and paid) for using RStudio is provided by RStudio Cloud, \cite{allaire2022}, which also offers an instructor's account for creating virtual classrooms. RStudio Cloud now offers a real-time collaboration feature for shared projects. RStudio Cloud also offers an \textsf{R} interface to Python via the `reticulate` \textsf{R} package, which provides a comprehensive set of tools for interoperability between Python and \textsf{R} \cite{ushey}. Thus, one can use both \textsf{R} and Python code cells in the same R Markdown (or Quarto) document, combining the power of both. With R Markdown, one can even create websites, blogs and books, using the `blogdown` and `bookdown` packages. For more details, see the resources tab on the RStudio website \cite{allaire2021}. 



# Kepler's Laws

Johannes Kepler was the young assistant of the 16th century Danish astronomer Tycho Brahe (1546 - 1601), considered the father of modern astronomy. Brahe had the amazing skill of being able to measure planetary position, by naked eye and his well-designed instruments, with amazing accuracy, as the telescope was not invented until 1608. 

Brahe made very accurate and comprehensive astronomical observations, but it took the mathematical genius of Kepler and two decades of hard work to fit Brahe's data to three simple empirical laws of planetary motion: 

1. **First law**: Kepler discovered that the orbit of Mars was an ellipse and he generalized this observation that every planet has an elliptical orbit with the Sun at one of its foci. See Figure \@ref(fig:kepler2).
2. **Second law**: The radius vector from the Sun to a planet sweeps out equal areas in equal times, implying that the rate of change (with respect to time) of the area swept by the radius vector of the planet's orbit is constant.
3. **Third law**: The orbital period $T$ of a planet revolving around the Sun is related to the average distance from the Sun, $D$ of its elliptical orbit by $D^3 = K T^2$, where $K$ is constant across all planets. 

In 1609 Kepler published the first two laws of planetary motion in *Astronomia Nova* \cite{frank2010}, where he described his discoveries and how he dealt with noisy data to make the scientific conclusions known as Kepler's laws. This was an early example of what we now call *the scientific method*. In 1619 he published *Harmonices Mundi* (The Harmony of the World) where he describes his "third law" of planetary motion \cite{kepler1997}.

Kepler's second law proved crucial to Isaac Newton (1643 - 1727), when he derived from empirical observations his universal law of gravitation, first published in his *Principia* in 1687. In fact, Newton showed that the motion of bodies subject to central gravitational force need not always follow elliptical orbits, but can also have parabolic or hyperbolic orbits, depending on the total energy of the body. Thus, an object with sufficiently high energy, such as a comet, can enter the solar system and leave without ever returning. For more details and a video by the physicist Brian Green demonstrating how Newton's law of gravitation determines the trajectories of the planets, we refer the reader to \cite{britannica}. 

```{r kepler2, echo = FALSE, out.width = "115px", fig.align='center', fig.cap="Kepler's laws for planetary motions. Source: Wikipedia."}
#library(rsvg)
#rsvg_png("Kepler_laws.svg", "Kepler_laws.png")
knitr::include_graphics("images/Kepler_laws.png")
```

We list below some important observations about Kepler's laws: 

- Even a comet obeys Kepler's 3rd law, and from its period one can calculate the average distance of the comet to the Sun.
- Kepler's laws can be derived from Newton's laws of motion and his law of gravity.
- Newton's law of gravity can also be derived from Kepler's first two laws. 
- Kepler's third law allows us to find the most efficient trajectory from Earth to Mars, which is called the Hohmann transfer orbit. Kepler's third law implies that this orbit has to be an ellipse that touches both orbits and has the shortest possible semimajor axis. 

For more details on Kepler's laws, one can explore the freely available online Physics Bootcamp \cite{ling2022}. 



# Discovering Kepler's 3rd Law

## Visualizing Planetary Data from NASA

In this activity, we illustrate how *Kepler's Third Law of Planetary Motion* can be discovered using *least squares* to fit a mathematical model to real planetary data from NASA's Lunar and Planetary Science Division \cite{williams2022}. The planetary data in Table \@ref(tab:table1) were derived from the raw NASA data by doing data transformations that consist of normalizing the distances and the orbital periods in Earth's units (1AU = $1.496\times 10^8$ km) \cite{williams2022a}. We give the raw planetary data from NASA in the code chunk below, and in the following code cell we normalize the data. 

\vspace{1mm}

```{r, echo=TRUE}
# Raw planetary data: distance is given in units of 10^6 km, and period in days
dist<-c(57.9,108.2,149.6,227.9,778.6,1433.5,2872.5,4495.1,5906.4) # in 10^6 km
period<-c(88,224.7,365.2,687,4331,10747,30589,59800,90560) # in Earth's days
```


```{r table1, echo=FALSE, warning=FALSE, message=FALSE}
dist<-c(57.9,108.2,149.6,227.9,778.6,1433.5,2872.5,4495.1,5906.4) # in 10^6 km
period<-c(88,224.7,365.2,687,4331,10747,30589,59800,90560) # in days
D<-dist/dist[3] # normalized distance in AU relative to Earth
T<-period/period[3] # normalized period in years relative to Earth
planet<-c("Mercury","Venus","Earth","Mars","Jupiter","Saturn","Uranus","Neptune","Pluto") 
dataDT<-data.frame(D, T, log(D), log(T)) # column-bind into a dataframe
row.names(dataDT)<-planet # use planet names as the row names
colnames(dataDT)<-c("Distance D [AU]", "Period T [Earth's Years]", "ln(D)", "ln(T)") 
# print a table of normalized planetary data
knitr::kable(dataDT, booktabs=T, format="simple", caption = "NASA's Normalized Planetary Data") %>% 
  kable_styling(position = "center")
```


We can use the normalized planetary data to find a relationship between the average distance from the Sun, given in AU, and the orbital period, given in Earth's years. The code chunk below normalizes the planetary data, which is shown in Table \@ref(tab:table1). We can also visualize the normalized planetary data by creating a scatterplot of period vs. distance, see Exercise \@ref(exr:planets).  

\vspace{1mm}

```{r, echo=TRUE}
D<-dist/dist[3] # normalized distance in AU relative to Earth
T<-period/period[3] # normalized period in years relative to Earth
```



::: {.exercise #planets}
Implement the two code cells above, plus the code chunk below in an R Markdown document in RStudio, and create a scatterplot of the normalized planetary data shown in Table \@ref(tab:table1). Note that the `ggplot()` function is from the `ggplot2` package, a part of the `tidyverse` collection. Also note that we customized the colors of the planets as well as their relative sizes, mostly for fun.
:::

\vspace{1mm}

```{r planets, echo=TRUE, fig.show='hide', fig.align='center', fig.width=7, fig.height=3.3, fig.cap="The normalized planetary data."}
dataDT<-tibble(D,T) # column-bind D and T into a dataframe
colors<-c("black","brown","blue","red","orange","gold","lightblue","darkblue","black")
f <- 1.3 # a multiple to scale the planet sizes
sizes<-f*c(1/3,0.9,1,1/2,11,9,4,3.9,1/5) # relative planet sizes
ggplot() +
  geom_point(mapping=aes(x=D,y=T),data=dataDT,col=colors,size=sizes,alpha=0.6) +
  labs(x ="Distance D [AU]", y = "Orbital Period T [years]") +
  theme(axis.text=element_text(size=7), axis.title=element_text(size=8))
```


It is often a good idea to transform the data and visualize the relationship between the transformed data in our pursuit to discover any useful patterns. Many laws of nature are in the form of power laws, thus transforming the data to a log-log scale by taking logarithms of both distance and period, is a natural transformation to consider. The natural logarithms of distance and period are given in Table \@ref(tab:table1), and the log-log plot is shown in Figure \@ref(fig:log-log). 


```{r log-log, echo=FALSE, fig.align='center', fig.width=6, fig.height=2.4, fig.cap="The normalized planetary and simulated asteroid data on a log-log scale."}
colors<-c("black","brown","blue","red","orange","gold","lightblue","darkblue","black")
f <- 2 # a multiple to scale the planet sizes
sizes<-f*c(1/3,0.9,1,1/2,11,9,4,3.9,1/5)
N<-50 # number of asteroids to plot
Dasteroids<-runif(N,2.2,3.3) # random distances from U(2.2,3.3) in AU
Tasteroids<- Dasteroids^(3/2) # Kepler's 3rd law for the asteroid periods in Earth years
ggplot() +
  geom_point(mapping=aes(x=log(D),y=log(T)),data=dataDT,col=colors,size=sizes,alpha=0.6) +
  labs(x ="log(D)", y = "log(T)") +
  geom_point(mapping = aes(x=log(Dasteroids),y=log(Tasteroids)), col="black", pch=20, size=runif(N,min=0,max=1/13*f), alpha=0.5) +
  theme(axis.text=element_text(size=7), axis.title=element_text(size=8))
```


Note that on the log-log scale Earth is located at $(0,0)$ since the data is normalized relative to Earth. What is more interesting is that all the planets seem to be positioned along a straight line, and this is a strong evidence that the original data must satisfy a power law. It is also curious that there is a noticeable larger gap between Mars and Jupiter. This is the region of the solar system where the *asteroid belt* is located. It is believed that the asteroids in the main belt are remnants of a protoplanetary disk that never formed a planet, but they could also be the remnants of an ancient planet. The main belt, where the orbits are more stable, is between 2.2 and 3.3 AU from the Sun. For example, Ceres, which is the largest of the asteroids, about 1/13 the size of Earth, considered to be a dwarf planet, is located about 2.8 AU from the Sun, and has a period of 4.6 Earth years. Figure \@ref(fig:log-log) shows a small sample from the asteroid belt between Mars and Jupiter, based on simulated data.  


::: {.exercise #fun}
Extend the \textsf{R} code from Exercise \@ref(exr:planets) to replicate Figure \@ref(fig:log-log). To generate a random sample of average distances of the asteroids from the Sun, generate a sample of size 50 from the uniform distribution on the interval $(2.2,3.3)$ with the help of the \textsf{R} function `runif()`, and use Kepler's third law to generate the corresponding periods. Use the `geom_point()` function to add the asteroids to the log-log plot of the planets. For the size of the points representing the asteroids, use the fact that the largest asteroids like Ceres are about 1/13 the size of Earth.
:::

Note that Exercise \@ref(exr:fun) offers a fun way to exploit R's capabilities to create a visual representation of the asteroid belt. However, this is a departure from our efforts to "discover" Kepler's third law. Keep in mind that Figure \@ref(fig:log-log) is not representative of the actual asteroids since we are not using empirical data, and we are actually using Kepler's third law to position them on the plot.



## Kepler's 3rd Law from Normalized Planetary Data

As we already observed, Figure \@ref(fig:log-log) shows that all planets are located very precisely along a straight line on the log-log scale, and this implies that the original data for distances and periods may satisfy a power law. Thus, for the model function, we can use a power model with two parameters $\alpha$ and $\beta$:

\begin{equation}
T=\alpha D^{\beta}, (\#eq:powmodel1)
\end{equation}

where $T$ is the orbital period in Earth's years and $D$ is the average distance from the Sun in AU. The data for Earth must satisfy this power model, but since the planetary data is normalized relative to Earth, both the Earth period $T_{\oplus}=1$ and average distance from the Sun $D_{\oplus}=1$, thus $\alpha =1$, and we are left with only the $\beta$ parameter to estimate from the normalized planetary data. We can linearize the power model \@ref(eq:powmodel1) with $\alpha=1$ by taking the natural logarithm on both sides. Now, we have an equation of a line on the log-log scale: 

\begin{equation}
\ln(T) = \beta \ln(D) (\#eq:linmodel1)
\end{equation} 

This is a linear model with respect to the unknown parameter $\beta$. The response variable is now $y=\ln(T)$, and the predictor variable is $x=\ln(D)$. Thus, the linearized model can be written as:

\begin{equation}
y = \beta x (\#eq:linmodel2)
\end{equation}

**Instructional Note:** Let us emphasize that if we do not normalize the planetary data, we would not be able to eliminate the parameter $\alpha$ the way we did. However, normalizing the data relative to Earth, prevents us from obtaining Kepler's law in its absolute form, being the more general power law \@ref(eq:powmodel1). For instructional purpose, we consider both approaches, with and without normalization. The non-normalized case will be developed in Section \@ref(sec:rawdata). 

Normalizing the data removes the parameter $\alpha$, since if the original data satisfies \@ref(eq:powmodel1), then the ratios, relative to Earth's data, satisfy the reduced model: 

\begin{equation}
\frac{T}{T_{\oplus}} = \left ( \frac{D}{D_{\oplus}} \right ) ^{\beta} (\#eq:powmodel2)
\end{equation}

The reduced model \@ref(eq:powmodel2) for the normalized data was linearized in \@ref(eq:linmodel2), using a log-transformation on both variables. More generally, if $N$ is the number of data points (9 in this case), how can we estimate the value of $\beta$ from the values $x_j=\ln(D_j)$ and $y_j=\ln(T_j)$ for $j=1,\ldots,N$?

Ideally, we want all pairs of $x$ and $y$ values to satisfy the model in \@ref(eq:linmodel2), thus the linear system:

\begin{equation}
\begin{matrix}
\beta x_1 & =       & y_1 \\
          & \vdots  &     \\
\beta x_N & =       & y_N \\
\end{matrix}
\iff
\beta 
\begin{bmatrix}
x_1   \\
\vdots \\
x_N
\end{bmatrix}
=
\begin{bmatrix}
y_1   \\
\vdots \\
y_N
\end{bmatrix} 
\iff \beta \mathbf{x} = \mathbf{y} (\#eq:betasystem1)
\end{equation}

However, this overdetermined system has no solution in general. So, how do we "solve" a linear system that does not have a solution? 

One geometrical way of thinking about finding a solution, in some sense, to a system like \@ref(eq:betasystem1) that does not have a solution, is to use *orthogonal projections*. Observe that the linear system \@ref(eq:betasystem1) does not have a solution, because the $\textbf{y}$ vector in \@ref(eq:betasystem1) is not a multiple of the $\textbf{x}$ vector, in general. However, if we project orthogonally the $\textbf{y}$ vector onto the $\textbf{x}$ vector, as shown in Figure \@ref(fig:2Dproj), then we can find a number $\beta$ such that: 

\begin{equation}
\textit{Proj}_{\textbf{x}}\textbf{y} = \beta \textbf{x} (\#eq:proj)
\end{equation}


```{r 2Dproj, echo = FALSE, out.width = "90px", fig.align='center', fig.cap="The orthogonal projection of \\textbf{y} onto the line spanned by \\textbf{x}."}
knitr::include_graphics("images/projection2D.jpg")
```


The orthogonal projection of $\textbf{y}$ onto $\textbf{x}$ is done by taking the *dot product* of $\textbf{y}$ with the unit vector $\frac{\textbf{x}}{\|\textbf{x}\|}$, and using the resulting number as a multiple for the unit vector $\frac{\textbf{x}}{\|\textbf{x}\|}$ to give us the projected vector: 

\begin{equation}
\textit{Proj}_{\textbf{x}}\textbf{y} = \frac{\textbf{x}\cdot \textbf{y}}{\|\textbf{x}\|} \, \frac{\textbf{x}}{\|\textbf{x}\|} = \frac{\textbf{x}\cdot \textbf{y}}{\|\textbf{x}\|^2} \, \textbf{x}
= \frac{\textbf{x}\cdot \textbf{y}}{\textbf{x}\cdot \textbf{x}} \, \textbf{x} (\#eq:projformula)
\end{equation}

Compared with \@ref(eq:proj), the projection formula in \@ref(eq:projformula) gives us at once a formula for the $\beta$ value:

\begin{equation}
\beta = \frac{\textbf{x}\cdot \textbf{y}}{\textbf{x}\cdot \textbf{x}} = \frac{\sum_{j=1}^N x_j y_j}{\sum_{j=1}^N x_j^2} (\#eq:betaformula)
\end{equation}

Note that dividing by zero in \@ref(eq:betaformula) does not happen as long as we are dealing with a non-trivial problem having a non-zero vector $\textbf{x}$. Also note that in the one-parameter linear model, the *line of best fit* $y=\beta x$ that we found, using an orthogonal projection, does not coincide with the line that goes through the center of mass of the data. It turns out that for linear models with two parameters, using orthogonal projections leads to the line of best fit, which does go through the center of mass of the data, as we show later. 

There is an equivalent way of thinking about orthogonal projections in terms of minimizing the length of vectors. Consider an arbitrary multiple $\beta$ of the given $\textbf{x}$ vector, that is $\beta\textbf{x}$, and take the difference with the given vector $\textbf{y}$. Minimizing the Euclidean length of this difference $\|\textbf{y} - \beta\textbf{x}\|$ with respect to the parameter $\beta$ is equivalent to finding the orthogonal projection of $\textbf{y}$ onto $\textbf{x}$ in which case the minimum length of the difference is achieved, i.e. 

\begin{equation}
\text{Min}_{\beta}\, \|\textbf{y} - \beta\textbf{x}\| = \|y-\textit{Proj}_{\textbf{x}}\textbf{y}\| \text{ for some }\hat{\beta} \text{ such that } \textit{Proj}_{\textbf{x}}\textbf{y} = \hat{\beta} \textbf{x} (\#eq:min)
\end{equation} 


We can generalize the idea of taking orthogonal projections to linear models with many parameters, which leads to multiple linear regression. Remember that a linear model in this context refers to being linear with respect to the model parameters.


We can compute orthogonal projections in \textsf{R}  using the `project()` function from the `mosaic` \textsf{R}  package. The `project()` function can be used for either:

 1. Given `project(y,x)`, it projects `y` onto `x`, and returns the projected vector.
 2. Given a formula (specified by `~`) as an argument, it works like the base \textsf{R} linear model function `lm()`, by constructing a model matrix whose columns are the vectors on the right-hand side of the formula for the more general case of multiple linear regression. For example, if we consider the formula `y~x1+x2+x3` for multiple linear regression, then `project(y~x1+x2+x3)` projects the vector `y` onto the column space of the model matrix whose columns are the vectors `x1`, `x2`, and `x3`. In this case, the result is the vector of the projection coefficients, for each of the column vectors in the model matrix. 

In our case, we use option (2) with `project(y~x)` and since we are projecting the vector `y` onto the single vector `x`, the result is the single coefficient $\beta$ such that $\textit{Proj}_{\textbf{x}}\textbf{y} = \beta \textbf{x}$: 

\vspace{1mm}

```{r}
x<-log(dataDT$D)   # x=log(D)
y<-log(dataDT$T)   # y=log(T)
beta<-project(y~x) # project y onto x to get the coefficient beta of x
```

This way, we get an estimate for $\beta \approx `r round(beta,4)`$, and the fitted model becomes:

```{=tex}
\begin{equation}
T = D^{`r round(beta,4)`} (\#eq:fitmodel)
\end{equation}
```

Note that $\beta$ is very close to $1.5$, and the fitted model \@ref(eq:fitmodel) is unitless since $T$ and $D$ are relative to Earth. This is a variation of what Kepler discovered about 400 years ago. 

After laboring for 17 years on the observations of Brahe, Kepler discovered the Third Law of planetary motion on May 15, 1618. He wrote the following about this moment:

> "at first I believed I was dreaming ... But it is absolutely certain and exact that the proportion between the periodic times of any two planets is precisely the sesquialterate (in a ratio of three to two) proportion of their mean distances." From Kepler's _The Harmony of the World_ (1619) \cite{kepler1997}. 

However, Kepler does not reveal how he reached his conclusion that the power must be exactly $3/2$. 


## Kepler's 3rd Law from Raw Planetary Data {#sec:rawdata}

Next, we explore the following question: 

- What happens if we do not normalize the planetary data relative to Earth?

Now, we have to work with the raw `dist` and `period` data vectors, instead of the normalized vectors `D` and `T`. We also have to consider the more general power law \@ref(eq:powmodel1) since we cannot imply anymore that $\alpha=1$. We can linearize the power model \@ref(eq:powmodel1), just like before, by taking the natural logarithm on both sides. We obtain again an equation of a line on the log-log scale, but this time with a non-zero $y$-intercept: 

\begin{equation}
\ln(T) = \ln(\alpha) + \beta \ln(D) (\#eq:linmodel3)
\end{equation} 

This is still a linear model with respect to the unknown parameters $\gamma = \ln(\alpha)$ and $\beta$. The response variable is again $y=\ln(T)$, represented by the raw data vector `log(period)`, and the predictor variable is $x=\ln(D)$, represented by the raw data vector `log(dist)`. Thus, the linearized model can be written as:

\begin{equation}
y = \gamma + \beta x (\#eq:linmodel4)
\end{equation}


Just as before, we want all pairs of $x$ and $y$ values to satisfy the model in \@ref(eq:linmodel4), thus the linear system:

\begin{equation}
\begin{matrix}
\gamma + \beta x_1 & =       & y_1 \\
          & \vdots  &     \\
\gamma +  \beta x_N & =       & y_N \\
\end{matrix}
\iff
\gamma 
\begin{bmatrix}
1   \\
\vdots \\
1
\end{bmatrix}
+ \beta 
\begin{bmatrix}
x_1   \\
\vdots \\
x_N
\end{bmatrix}
=
\begin{bmatrix}
y_1   \\
\vdots \\
y_N
\end{bmatrix} 
\iff \gamma \textbf{1} + \beta \textbf{x} = \textbf{y} (\#eq:betasystem2)
\end{equation}

Of course, this overdetermined system has no solution in general since the vector $\textbf{y}$ is not a linear combination of the vectors $\textbf{1}$ (the vector of ones) and $\textbf{x}$, in general. So, again we want to "solve" a linear system that does not have a solution. We can generalize the idea of orthogonal projection, we used for the single parameter model. The idea is again to project orthogonally the vector $\textbf{y}$, but this time onto the subspace $\text{Im}(A)=\langle \textbf{1},\textbf{x}\rangle$ spanned by the vectors $\textbf{1}$ and $\textbf{x}$, and let us denote this orthogonal projection by $\boldsymbol{\pi} = \textit{Proj}_{\langle \textbf{1},\textbf{x}\rangle}\textbf{y}$, see Figure \@ref(fig:3Dproj). In this notation, $A$ represents the model matrix with columns $\textbf{1}$ and $\textbf{x}$. That way we get a consistent linear system that we can solve to find estimates for the two parameters. So, we want to solve the linear system: 

\begin{equation}
\gamma \textbf{1} + \beta \textbf{x} = \textit{Proj}_{\langle \textbf{1},\textbf{x}\rangle}\textbf{y} = \boldsymbol{\pi}  (\#eq:pi)
\end{equation}

```{r 3Dproj, echo = FALSE, out.width = "125px", fig.align='center', fig.cap="The orthogonal projection of \\textbf{y} onto $\\text{Im}(A)=\\langle \\textbf{1},\\textbf{x}\\rangle$."}
knitr::include_graphics("images/projection3D.jpg")
```


We assume that $\textbf{1}$ and $\textbf{x}$ are linearly independent, which is usually the case, provided that not all components of $\textbf{x}$ are the same (having non-zero variance). Observe that $\gamma$ and $\beta$ are the coordinates of the projection relative to the vectors $\textbf{1}$ and $\textbf{x}$. 

Assume now that the components of $\textbf{x}$ sum to zero, that is, $\sum_{j=1}^N x_j = 0$, which is equivalent to $\bar{x}=0$, or $\textbf{1} \cdot \textbf{x}=0$. Since the dot product is zero, the vectors are orthogonal. Thus, the orthogonal projection of $\textbf{y}$ onto the subspace $\langle \textbf{1},\textbf{x}\rangle$ can be found by computing the individual orthogonal projections onto the basis vectors.


::: {.exercise }
Take the dot product of \@ref(eq:pi) first with $\textbf{1}$ and then with $\textbf{x}$, and use that $\textbf{1} \cdot \textbf{x}=0$ to derive:
\begin{equation}
\gamma = \frac{\boldsymbol{\pi}\cdot \textbf{1}}{\textbf{1} \cdot \textbf{1}}, \quad \beta = \frac{\boldsymbol{\pi}\cdot \textbf{x}}{\textbf{x} \cdot \textbf{x}} (\#eq:gammabeta)
\end{equation} 
Note that $\textbf{1} \cdot \textbf{1}=N$ and $\textbf{x} \cdot \textbf{x}=\|\textbf{x}\|^2$. 
:::


::: {.exercise}
Since $\boldsymbol{\pi}$ is the orthogonal projection of $\textbf{y}$ on the subspace $\langle \textbf{1},\textbf{x}\rangle$, it follows that $\textbf{y} - \boldsymbol{\pi} \perp \langle \textbf{1},\textbf{x}\rangle$. Thus, $\textbf{y} - \boldsymbol{\pi} \perp  \textbf{1}$ and $\textbf{y} - \boldsymbol{\pi} \perp  \textbf{x}$, but this implies $(\textbf{y} - \boldsymbol{\pi}) \cdot \textbf{1} = 0$ and $(\textbf{y} - \boldsymbol{\pi}) \cdot \textbf{x} = 0$. Use this observation and \@ref(eq:gammabeta) to get the following formulas for the parameters:

\begin{equation}
\gamma = \frac{\textbf{y} \cdot \textbf{1}}{N} = \bar{y}, \quad \beta = \frac{\textbf{y}\cdot \textbf{x}}{\|\textbf{x}\|^2} (\#eq:gammabeta1)
\end{equation} 
:::

Thus, the line of best fit to the data when $\bar{x}=0$, based on orthogonal projections, is given by:

\begin{equation}
y=\bar{y} + \frac{\textbf{y}\cdot \textbf{x}}{\|\textbf{x}\|^2}\, x, \text{ provided that } \bar{x}=0 (\#eq:bestfit)
\end{equation} 

In the general case when $\bar{x}\neq 0$, we can simply shift the $x$ variable by the sample mean $\bar{x}$ of the data vector $\textbf{x}$. More generally, we consider the linear (w.r.t $\gamma$ and $\beta$) model:

\begin{equation}
y = \gamma + \beta (x - \bar{x}) (\#eq:model)
\end{equation}

\vspace{1mm}

```{exercise hw} 
Use the projection $\boldsymbol{\pi} = \textit{Proj}_{\langle \textbf{1},\textbf{x}-\bar{x}\textbf{1}\rangle}\textbf{y} = \gamma \textbf{1} + \beta (\textbf{x} - \bar{x}\textbf{1})$, where $\textbf{x}-\bar{x}\textbf{1}$ is the vector of $x$ coordinates shifted by the sample mean $\bar{x}$, and follow the logic and the methods we used when $\bar{x}=0$ to show the following:

\begin{align}
& 1. \quad \textbf{1} \perp (\textbf{x} - \bar{x}\textbf{1}) \\
& 2. \quad (\textbf{y} - \boldsymbol{\pi}) \perp \textbf{1} \text{ and } (\textbf{y} - \boldsymbol{\pi}) \perp (\textbf{x} - \bar{x}\textbf{1}) \\
& 3. \quad  \gamma = \frac{\textbf{y} \cdot \textbf{1}}{N} = \bar{y}, \quad \beta = \frac{\textbf{y}\cdot (\textbf{x} -\bar{x}\textbf{1})}{(\textbf{x} -\bar{x}\textbf{1})\cdot (\textbf{x} -\bar{x}\textbf{1})} = \frac{\textbf{y}\cdot \textbf{x} - N\bar{x}\bar{y}}{\|\textbf{x}\|^2 - N(\bar{x})^2} = r_{xy}\frac{s_y}{s_x}\\
& 4. \text{ the line of best fit (the regression line): } \boxed{y = \bar{y} + r_{xy}\,\frac{s_y}{s_x}(x-\bar{x})}, (\#eq:bestfit1)
\end{align}

where $r_{xy}$ is the sample correlation between the data vectors $\textbf{x}$ and $\textbf{y}$; $s_y$ and $s_x$ are the sample standard deviations whose definitions are given below.

\begin{align}
r_{xy} & = \frac{(\textbf{x} - \bar{x}\textbf{1})\cdot (\textbf{y} - \bar{y}\textbf{1})}{\|\textbf{x} - \bar{x}\textbf{1}\|\,\|\textbf{y} - \bar{y}\textbf{1}\|} = \frac{\textbf{y}\cdot \textbf{x} - N\bar{x}\bar{y}}{(N-1)s_x s_y} \\
s_x^2 & = \frac{1}{N-1}\|\textbf{x} - \bar{x}\textbf{1}\|^2 = \frac{1}{N-1} (\|\textbf{x}\|^2 - N(\bar{x})^2)
\end{align}

Note that the line of best fit in \@ref(eq:bestfit1) implies that the center of mass of the data $(\bar{x},\bar{y})$ lies on the line. Also, the sample correlation has a simple geometrical interpretation, namely: it is the orthogonal projection of the centralized (mean zero) vector $\textbf{y}-\bar{y}\textbf{1}$ onto the centralized (mean zero) vector $\textbf{x}-\bar{x}\textbf{1}$, both normalized to unit vectors. This makes it clear why the sample correlation is in the range $[-1,1]$. The sample standard deviation is simply the normalized length of the centralized, mean zero, vector. 
```


We can now fit the model in \@ref(eq:model) to the raw planetary data, either by using the formulas from Exercise \@ref(exr:hw) or by using the \textsf{R} function `project()` from the `mosaic` package. 

\vspace{1mm}

```{r}
y<-log(period) # log of raw period data
x<-log(dist)   # log of raw distance data
xc<-x-mean(x) # centralized, mean zero vector
project(y~1+xc) # project y onto the span of 1 and xc
```

In the function call `project(y~1+xc)`, the vector `xc` has been centralized to have mean zero, and the formula object `y~1+xc` means to project the vector `y` onto the span of the vectors `1` and `xc`. Note that \textsf{R}  turns the number `1` into a vector of ones, of the same size as `xc`. The function call returns the coordinates $\gamma$ and $\beta$, w.r.t. the basis vectors `1` and `xc`, being the $y$-intercept and the slope parameters of the linear model in \@ref(eq:model). 

The results from Exercise \@ref(exr:hw) give us another way to compute the parameters, as shown below. 

\vspace{1mm}

```{r}
gamma <- mean(y) # y-intercept = sample mean of y
beta <- cor(x,y)*sd(y)/sd(x) # slope of line of best fit
```

In the code chunk above, we used the base \textsf{R}  function `cor(x,y)`, which computes the sample correlation between `x` and `y`, as well as the `sd(y)`, which computes the sample standard deviation of `y`. 

Using the optimal values for $\gamma=\bar{y}=`r round(gamma,4)`$ and $\beta = r_{xy}\frac{s_y}{s_x}=`r round(beta,4)`$, we can exponentiate the fitted linear model \@ref(eq:model). In this notation, $T$ and $D$ represent the original (not normalized) period and distance variables. 

\begin{equation}
\ln(T)  = \gamma + \beta (\ln(D) - \bar{x}) \implies T = e^{\bar{y} - \beta \bar{x}} D^{\beta} = \alpha D^{\beta}, (\#eq:fitmodel1)
\end{equation}

where $\beta \approx 1.4988$, and $\alpha = e^{\bar{y} - r_{xy}\frac{s_y}{s_x}\bar{x}} \approx 0.2007$. 

In \@ref(eq:fitmodel1), $T$, $\alpha$ and $D$ have units, and one can use *dimensional analysis* to show that $\beta$ must be exactly $3/2$. Dimensional analysis can be very useful to check the correctness of an equation that we have derived after some algebraic manipulations. More importantly, dimensional analysis can be used to determine the form of an equation itself. This goes a bit beyond the scope of our presentation as it requires some additional physics knowledge, but we shall try to illustrate its use in the context of Kepler's 3rd Law. The key observation is that most physical quantities can be expressed in terms of combinations of basic dimensions such as mass ($M$), length ($L$), time ($T$), etc. Note that the term "dimension" is not quite the same as a "unit", but they are closely related. For example, the unit of force is Newton (N), which can be expressed in terms of more basic units as $\text{N} = \text{kg}\times \text{m}\times \text{s}^{-2}$, and the dimension of force is $MLT^{-2}$. The key step in dimensional analysis is to guess the form of a given quantity of interest as a power law involving all quantities that the main quantity should depend on. The period $P$ of a planet orbiting the Sun should depend on the average distance $D$ to the center of the Sun, the mass $M_0$ of the Sun, and the gravitational constant $G$. Note that we used the letter $P$ to represent the orbital period, rather than $T$, since we want to use $T$ to represent the time dimension in our dimensional analysis. The most general power law that involves these quantities is given by:

\begin{equation}
P = k M_0^a D^b G^c, (\#eq:guess)
\end{equation}
   
where $k$ is a dimensionless constant, and $a$, $b$ and $c$ are powers to be determined. The dimensions of $G$ are $[\text{N}] L^2 M^{-2}$, which can be determined from Newton's Law of Gravity, where the dimensions of force are $[\text{N}]=MLT^{-2}$, so the dimensions of $G$ are $MLT^{-2}L^2 M^{-2}=L^3 M^{-1}T^{-2}$. Substitute in \@ref(eq:guess) to get: 

$$T = k M^a L^b (L^3 M^{-1}T^{-2})^c = k M^{a-c}L^{b+3c}T^{-2c}$$

Comparing terms and powers yields:

$$a-c=0,\, b+3c=0, \, 1=-2c \implies a=c=-1/2, \, b= 3/2$$
Thus, the power law in \@ref(eq:guess) becomes:

\begin{equation}
P = \frac{k}{\sqrt{M_0 G}}D^{3/2}, (\#eq:guess1)
\end{equation}

And Kepler's 3rd law of planetary motion emerges from \@ref(eq:guess1): 

\begin{equation}
D^3 = \frac{GM_0}{k^2} P^2 (\#eq:Kepler)
\end{equation}

If we consider the special case of a circular motion around the Sun, we can get that $k^2=4\pi^2$. Note that this dimensional analysis requires knowing Newton's Law of Gravity. 



::: {.exercise #plot}
Create a plot of the raw planetary data and superimpose the graph of the fitted model \@ref(eq:fitmodel1), as shown in Figure \@ref(fig:linfit). Optionally, add some random asteroids that obey Kepler's 3rd law. 
:::

::: {.solution}
The code for Exercise \@ref(exr:plot) is given below. 

```{r linfit, eval=TRUE, echo = FALSE, fig.align='center', fig.width=7, fig.height=3.5, fig.cap="The fitted power model superimposed on the raw planetary data."}
########################### Solution to Exercise 3.6 ##########################
# colors for the planets
colors<-c("black","brown","blue","red","orange","gold","lightblue","darkblue","black")
raw_data<-tibble(dist,period) # raw planetary data
y<-log(period)  # log of raw period data
x<-log(dist)  # log of raw distance data
beta <- cor(x,y)*sd(y)/sd(x)  # slope of line of best fit
a<-exp(mean(y) - cor(x,y)*sd(y)/sd(x)*mean(x))
K<-1/a^2  # Kepler's constant without converting 10^6 km to AU
# D for model graph in 10^6 km, relative to Earth
Dmodel <- dist[3]*seq(from=0.1, to=40, length = 200) 
Tmodel <- a*Dmodel^beta  # T for model graph in days
grid <- tibble(Dmodel,Tmodel)  # grid of D and T values for the model
# Optionally add some random asteroids using Kepler's 3rd law
N<-30  # number of random asteroids to plot
Dasteroids <-dist[3]*runif(N,2.2,3.3)  # random distances in 10^6 km
Tasteroids <- a*Dasteroids^beta  # Kepler's 3rd law for the asteroid periods
f <- 1.4  # a multiple to scale the planet sizes
sizes<-f*c(1/3,0.9,1,1/2,11,9,4,3.9,1/5)  # planet sizes
# create the plot
ggplot() +
  geom_line(mapping=aes(x=Dmodel,y=Tmodel),data=grid,col="blue",size=0.5,alpha=0.6)+
  geom_point(mapping=aes(x=dist,y=period),data=raw_data,col=colors,size=sizes,alpha=0.6)+
  labs(x ="average distance from the Sun [millions km]",y = "period [days]")+
  geom_point(mapping=aes(x=Dasteroids,y=Tasteroids),col="black",size=1/13*f,alpha=0.6)+
  theme(axis.text=element_text(size=7), axis.title=element_text(size=8))
```


```{r, eval=FALSE, echo = TRUE}
## Solution to Exercise 3.6 
# colors for the planets
colors<-c("black","brown","blue","red","orange","gold","lightblue","darkblue","black")
raw_data<-tibble(dist,period) # raw planetary data
y<-log(period)  # log of raw period data
x<-log(dist)  # log of raw distance data
beta <- cor(x,y)*sd(y)/sd(x)  # slope of line of best fit
a<-exp(mean(y) - cor(x,y)*sd(y)/sd(x)*mean(x))
K<-1/a^2  # Kepler's constant without converting 10^6 km to AU
# D for model graph in 10^6 km, relative to Earth
Dmodel <- dist[3]*seq(from=0.1, to=40, length = 200) 
Tmodel <- a*Dmodel^beta  # T for model graph in days
grid <- tibble(Dmodel,Tmodel)  # grid of D and T values for the model
# Optionally add some random asteroids using Kepler's 3rd law
N<-30  # number of random asteroids to plot
Dasteroids <-dist[3]*runif(N,2.2,3.3)  # random distances in 10^6 km
Tasteroids <- a*Dasteroids^beta  # Kepler's 3rd law for the asteroid periods
f <- 1.4  # a multiple to scale the planet sizes
sizes<-f*c(1/3,0.9,1,1/2,11,9,4,3.9,1/5)  # planet sizes
# Create the plot
ggplot() +
  geom_line(mapping=aes(x=Dmodel,y=Tmodel),data=grid,col="blue",size=0.5,alpha=0.6)+
  geom_point(mapping=aes(x=dist,y=period),data=raw_data,col=colors,size=sizes,alpha=0.6)+
  labs(x ="average distance from the Sun [millions km]",y = "period [days]")+
  geom_point(mapping=aes(x=Dasteroids,y=Tasteroids),col="black",size=1/13*f,alpha=0.6)+
  theme(axis.text=element_text(size=7), axis.title=element_text(size=8))
```

:::




# Discovering Kepler's 1st Law


## Kepler's Measurements of Mars

Project Mosaic \cite{kaplan} has on its website some legacy datasets that are not part of the `mosaicData` package, which gets installed along with the `mosaic` package. One of the datasets, named `kepler-mars.csv` contains measurements for the polar coordinates of Mars relative to the Sun, on the orbital plane of Mars. In addition to the historical measurements, the data also contain a modern reconstruction of the "actual" positions of Mars at the time Tycho Brahe made his very precise measurements, before even the telescope was invented. 

In Figure \@ref(fig:triangulation), Mars is shown only once as the point $M$, while the Earth's position is shown as $E_1$ and $E_2$, being the positions of Earth at the start and end of one Mars year, which Kepler estimated to be 687 Earth days. The angles $\angle M E_1 S$ and $\angle M E_2 S$ can be determined by observation, as can $\angle E_1 S E_2$ from knowledge of one Mars year. Trigonometry can then be used to solve for the Mars' distance $r$ from the Sun. When Kepler used this triangulation for Mars, he discovered that its distance from the Sun varies, and that its orbit is an ellipse with the Sun at one of its foci. In fact, it was Kepler who named the two centers in the ellipse "foci" ("focus" in Latin means "fireplace"). 


```{r triangulation1, echo = FALSE, eval=FALSE, out.width = "150px", fig.align='center', fig.cap="Planetary triangulation used by Kepler to find the distance of Mars from the Sun."}
knitr::include_graphics("images/triangulation.png")
```


```{r triangulation, echo = FALSE, out.width = "125px", fig.align='center', fig.cap="Planetary triangulation used by Kepler to find the distance of Mars from the Sun."}
knitr::include_graphics("images/triangulation-final.jpg")
```


::: {.exercise}
Read \cite{gingerich2011} to understand how Kepler did his triangulation of Mars. 
:::


::: {.exercise}
Load the `kepler-mars.csv` dataset from the `Data` tab on the Project Mosaic website \cite{kaplan}, and create the dataframe `Kepler` in RStudio, using the function `read.csv()`, having as argument the web address of the dataset.  
:::

::: {.solution}
Run the code below to load the `kepler-mars.csv` dataset and create the `Kepler` dataframe. 

```{r}
Kepler<-read.csv("http://www.mosaic-web.org/go/datasets/kepler-mars.csv")
```
:::


The dataframe `Kepler` has 28 observations and 6 variables, but we consider only the following three variables: 

- `kepler.radius`: The radius ($r$) of Mars, measured from the Sun in AU.
- `kepler.angle`: The polar coordinates angle ($\theta$) on the orbital plane of Mars, measured in radians, known as "true anomaly".
- `time`: The time interval in Earth days for the measurements, relative to a fixed day (presumably from the time Brahe made the original measurements).  


The computational explorations in the next two sections were inspired by the *MOSAIC Calculus* text \cite{kaplan2022}, which we used for a Calculus Lab. 


## Fitting an Ellipse to Kepler's Mars Data


Consider an ellipse with the Sun being in one of its foci. The polar form of the ellipse relative to the focus where the Sun is located, as the center of the coordinate system, is given in terms of the radius $r$ (originating from that focus of the ellipse) as a function of the angle $\theta$, measured relative to the major axis, which is related to the so called true anomaly. 

\begin{equation}
r = \frac{a}{1 + e \cos(\theta)} (\#eq:ellipse1)
\end{equation}

This form assumes that the reference direction $\theta = 0$ points towards the center. The parameters $a$ and $e$ describe the shape of the ellipse, and $e$ is called the **eccentricity**. Having zero eccentricity turns the ellipse into a circle of radius $a$. The equation of the ellipse in polar form given in \@ref(eq:ellipse1), corresponds to a coordinate system centered at one of the foci, with the angle $\theta$ measured, as shown in Figure \@ref(fig:ellipse). 


```{r ellipse, echo = FALSE, out.width = "115px", fig.align='center', fig.cap="An ellipse in polar form with the Sun in the left focus."}
knitr::include_graphics("images/kepler-ellipse-polar-2.png")
```


::: {.exercise}
Derive the polar form of the ellipse given in \@ref(eq:ellipse1). As a reference, use Section 9.4 *Conics in Polar Coordinates* in \cite{lippman2022}. 
:::


::: {.exercise}
Create a scatterplot of Mars' radius from the Sun, given by the variable `kepler.radius`, against the corresponding polar angle, given by the variable `kepler.angle`, as shown in Figure \@ref(fig:rtheta). Use the `gf_point()` plotting function from the `ggformula` package that gets installed with the `mosaic` package.
:::



::: {.solution}
The code below creates the scatterplot in Figure \@ref(fig:rtheta). Note that the function `gf_theme()` is a helper function used to control the size of the axis titles and axis text (marks), and `|>` is the pipe operator, which implements composition of functions. 



```{r rtheta, echo=TRUE, eval=TRUE, fig.width=4.2, fig.height=2.1, fig.cap="A scatterplot of Kepler's radius $r$, againsts Kepler's angle $\\theta$."}
gf_point(kepler.radius ~ kepler.angle, col="red", size=0.4, data=Kepler, 
         xlab="Kepler's angle [radians]", ylab="Kepler's radius [AU]") |>  
  gf_theme(axis.title = element_text(size = 7), axis.text = element_text(size = 6))
```
:::


::: {.exercise}
Estimate the values of the parameters $a$ and $e$ by fitting the model in \@ref(eq:ellipse1) to Kepler's data, using nonlinear least squares since the model depends nonlinearly on $e$ (it depends linearly on $a$). Use the `fitModel()` function from the `mosaic` package, and the fact that `kepler.radius` corresponds to the variable $r$, and `kepler.angle` corresponds to the variable $\theta$. The fitted model has the form:

```{r, echo=FALSE}
# fit an ellipse in polar coordinates to Kepler's data
fitted_model <- fitModel(kepler.radius ~ a/(1 + e*cos(kepler.angle)), 
                         start=list(a=mean(Kepler$kepler.radius),e=0), data=Kepler)
params<-coef(fitted_model) # fitted parameters
```

\begin{equation}
r = \frac{`r round(params[1],4)`}{1 + `r round(params[2],4)` \cos(\theta)} (\#eq:fitted)
\end{equation}

:::


::: {.solution}
Using the `fitModel()` function to fit the model in \@ref(eq:ellipse1) to Kepler's data is implemented by the code below, where the formula `kepler.radius ~ a/(1 + e*cos(kepler.angle))` specifies the model with the two parameters `a` and `e`. We provide starting values for `a` and `e` using the `start` argument, where we take the average Kepler's radius as the initial value of `a`, and zero as the initial value of `e`, given that the orbit of Mars is close to a circle. The resulting object `r_fun` is an \textsf{R} function with argument $\theta$, i.e. $r(\theta)$. The vector `params` contains the fitted parameters. In physics texts, the eccentricity of Mars is given as $0.093$.  

```{r, echo=TRUE}
# fit an ellipse in polar coordinates to Kepler's data
r_fun <- fitModel(kepler.radius ~ a/(1 + e*cos(kepler.angle)), 
                         start=list(a=mean(Kepler$kepler.radius),e=0), data=Kepler)
params<-coef(r_fun) # fitted parameters
params # print fitted coefficients
```

:::


Consider a Cartesian coordinate system where the Sun is located at the center $(0,0)$, and the position of Mars going around the Sun is given in polar coordinates by $(r,\theta)$. We can transform the polar $(r,\theta)$ into Cartesian $(x,y)$ coordinates using the relations $x = r \cos(\theta)$ and $y = r\sin(\theta)$.  

::: {.exercise}
Transform the polar coordinates of Mars `kepler.radius` and `kepler.angle` into Cartesian coordinates. Add the vectors of $x$ and $y$ coordinates to the `Kepler` dataframe, using the `mutate()` function from the `dplyr` package in the `tidyverse` collection. 
:::


::: {.solution}

The transformation from polar to Cartesian coordinates is implemented by the code below, where `mutate` allows us to add to the `Kepler` dataframe two new variables, `x` and `y`, which contain the $x$ and $y$ coordinates obtained from the corresponding polar coordinates. 

```{r}
Kepler <- Kepler |> 
            mutate(x=kepler.radius*cos(kepler.angle),y=kepler.radius*sin(kepler.angle))
```

:::


::: {.exercise}
The goal of this exercise is to plot the graph of the fitted ellipse \@ref(eq:fitted) on top of Kepler's data: 

- Plot the positions of Mars with `gf_point()`, using their $x$ and $y$ coordinates from `Kepler`.
- Add the Sun at the origin $(0,0)$ using the formula `0~0` with `col="yellow"` and big size (`size=12`). 
- Use the \textsf{R} function `r_fun()` for $r(\theta)$ returned by `fitModel()` to generate the vectors of $x$ and $y$ coordinates for a vector of $\theta$ values, generated with `theta<-seq(0,2*pi,len=200)` in radians. Use `gf_point()` to plot these 200 points that represent the fitted orbit of Mars, and replicate Figure \@ref(fig:marsorbit). 
:::


::: {.solution}
Figure \@ref(fig:marsorbit) is created with the code below. Note that the object `r_fun`, returned by the function `fitModel()`, is actually an \textsf{R} function $r(\theta)$ that implements the fitted ellipse in \@ref(eq:fitted). In particular, we can compute the Cartesian coordinates of the orbit of Mars using `r_fun(theta)*cos(theta)` for the $x$ coordinates, and `r_fun(theta)*sin(theta)` for the $y$ coordinates, where `theta` is a vector of 200 numbers from $[0,2\pi]$. Note that `0~0` plots a single point at $(0,0)$. 


```{r marsorbit,echo=TRUE, fig.width=3.2, fig.height=2.2, fig.cap="The fitted orbit of Mars superimposed on Kepler's data."}
# plot Kepler's data, the Sun, and the orbit of Mars
theta<-seq(0,2*pi,length=200) # 200 angle values
orbit<-tibble(xOrbit=r_fun(theta)*cos(theta),yOrbit=r_fun(theta)*sin(theta))
gf_point(yOrbit ~ xOrbit, data=orbit, col="pink", size=0.4, alpha=0.5) |> 
  gf_point(y ~ x, data=Kepler, col="red", size=0.8) |> 
  gf_point(0 ~ 0, size=12, col="yellow") +
  theme_void()
```

:::




# Discovering Kepler's 2nd Law

In this section, we want to explore how the area $dS$ swept by the radius vector joining Mars to the Sun depends on the small time interval $dt$. For this purpose, we want to use the 28 data points of `kepler.angle` and `time`, and create a continuous function of time using linear interpolation of our sparse data. We can create an \textsf{R} function `theta_fun()`, which interpolates the data linearly, by using the `connector()` function from the `mosaic` package, shown in the code below.  

```{r}
theta_fun <- connector(kepler.angle ~ time, data=Kepler)
```

In Figure \@ref(fig:theta), we visualize the graph of the function `theta_fun` using the `slipe_plot()` function from `mosaicCalc`, and superimpose it over the data points. Note where the data points are located. 

```{r theta, fig.height=2.8, fig.width=5.8, fig.align='center', fig.cap="The graph of $\\theta(t)$ superimposed over the data points."}
gf_point(kepler.angle ~ time, data=Kepler, size=0.6, col="blue") |> 
slice_plot(theta_fun(t) ~ t, domain(t=c(-789,4000)), 
           size=0.6, col="blue", alpha=0.5, n=1000) |>
  gf_labs(x = "time [days]", y="theta [radians]") +
  theme(axis.text=element_text(size=7), axis.title=element_text(size=8))
```

We use the \textsf{R} function `r_fun()`, returned by `fitModel()`, which implements the fitted ellipse $r(\theta)$ in \@ref(eq:fitted) to construct functions $x(t)$ and $y(t)$ that give the $x$ and $y$ coordinates of Mars' orbital position at time $t$. 

\begin{align}
x(t) & = r(\theta(t))\cos(\theta(t)) \\
y(t) & = r(\theta(t))\sin(\theta(t))
\end{align}

The function $\theta(t)$ is represented by the \textsf{R} function `theta_fun`, and $r(\theta(t))$ can be implemented by taking the composition of `r_fun` and `theta_fun`. The \textsf{R} functions `x_fun` and `y_fun` that implement $x(t)$ and $y(t)$ are given by the code below, where we use the `makeFun()` function from the `mosaic` package. 

```{r}
x_fun <- makeFun(r_fun(theta_fun(t))*cos(theta_fun(t)) ~ t)
y_fun <- makeFun(r_fun(theta_fun(t))*sin(theta_fun(t)) ~ t)
```


Now, we have the ability to generate the $x$ and $y$ coordinates of the point on the fitted ellipse at time $t$ as well as time $t+dt$ for some small time interval $dt$. This allows us to compute the area of the small triangle formed by the Sun and Mars at the two positions along the orbit. If the time interval $dt$ is small enough then the area of the triangle will be approximately equal to the area of the segment cut from the ellipse by the radius vector connecting the Sun with Mars. The area of the triangle is given by:

\begin{equation}
dS = \frac{1}{2}\det
\begin{vmatrix}
x_i & x_{i+1} \\
y_i & y_{i+1}
\end{vmatrix}
= \frac{1}{2}(x_i y_{i+1} - x_{i+1} y_i),
\end{equation}

where $(x_i,y_i)$ and $(x_{i+1},y_{i+1})$ are the coordinates of the points on the ellipse at times $t$ and $t+dt$.

Next, we sample $5000$ random time points $t$ within the range of the variable `time`, using the random number generator of the Uniform distribution on the interval $[-790,3000]$. Similarly, we generate $5000$ random values for the small time interval $dt$, sampled from the Uniform distribution on the interval $[0.1,0.5]$ to represent a small enough time interval between 1/10 and 1/2 of a day. Then, we can find the area $dS$ for all $5000$ pairs of $t$ and $dt$ by using the `x_fun()` and `y_fun()` functions evaluated at $t$ and $t+dt$. 

```{r}
set.rseed(2022) # set the random seed
t <- runif(5e3,-790,3000) # random times
dt <- runif(5e3,0.1,0.5) # random small time intervals
dS<-0.5*(x_fun(t)*y_fun(t+dt)-x_fun(t+dt)*y_fun(t)) # area of segment
```


Now, we can visualize the relationship between the area of the segment $dS$ and the small time interval $dt$ by plotting `dS` against `dt`, shown in Figure \@ref(fig:dSdt). 

```{r dSdt, fig.height=3, fig.width=5.8, fig.align='center', fig.cap="The scatterplot of $dS$ against $dt$ for a random sample of size 5000."}
mydata <-tibble(dS,dt) # bind dS and dt into a dataframe
gf_point(dS ~ dt, data=mydata, pch=20, size=0.1, col="blue", alpha=0.7) |> 
  gf_labs(x = "dt [days]", y="dS") +
  theme(axis.text=element_text(size=7), axis.title=element_text(size=8))
```


Notice how the sample of size $5000$ gets localized into 6 fairly well-defined linear trends. The bottom 5 trend-lines with the smallest slopes appear to correspond to the parts from the graph of $\theta(t)$ in Figure \@ref(fig:theta) within day 3000 that are either almost flat or have a small positive slope. Note that the bottom two trendlines over the $x$-axis can be distinguished on a bigger plot or if you zoom into the plot along the $y$-axis. The top-most linear trend with the highest slope corresponds to the parts of the graph of $\theta(t)$ where the actual data points are located, as can be seen from Figure \@ref(fig:theta), and this is the linear trend that we want to keep since the other 5 linear trends appear to be artifacts of the linear interpolation of our sparse data. We can filter the data for `dS` to extract only the top linear trend by observing that all values of `dS` for this linear trend appear to be above $0.001$. We can fit a line to the filtered data to find the slope of the linear trend. 

```{r}
# filter the data
mydata <- mydata |> 
  filter(dS > 0.001)
# linear regression on the filtered data
model<-lm(dS ~ dt, data=mydata)
```

We can add the regression line to the scatterplot of the filtered data with the code below. 

```{r trendline, fig.height=2.5, fig.width=5.5, fig.align='center', fig.cap="The regression line with slope $k_0=0.01056$, fitted to the filtered sample."}
gf_point(dS ~ dt, data=mydata, pch=20, size=0.1, col="blue", alpha=0.8) |>
  gf_lm(col="red", lwd=0.3, alpha=0.8) |> 
  gf_labs(x = "dt [days]", y="dS") + 
  theme(axis.text=element_text(size=7), axis.title=element_text(size=8))
```

The linear regression fit gives a slope of $k_0=`r round(coef(model)[2],5)`$, which can be accessed with `coef(model)`. 

Figure \@ref(fig:trendline) implies that the rate of change (with respect to time) of the area swept by the radius vector of the planet's orbit is approximately equal to the constant $k$ being the slope of the trendline, i.e. $\frac{dS}{dt} \approx k_0$. 

The exact statement of Kepler's 2nd law in this context can be stated as follows: 

\begin{equation}
\frac{dS}{dt} = \text{const} = k \implies \int_0^T dS = \int_0^T k dt \implies \pi AB = k T, (\#eq:rate)
\end{equation}

where $T$ is the orbital period of Mars, $\pi AB$ is the area of the ellipse, with $A$ being the semimajor axis, and $B$ the semiminor axis. Solving for $k$ gives:

```{r, echo=FALSE, eval=TRUE}
# Source: https://en.wikipedia.org/wiki/Semi-major_and_semi-minor_axes
A <- 1.52400 # semimajor axis of Mars in AU
B <- 1.51740 # semiminor axis of Mars in AU
T <- 686.980 # orbital period of Mars in Earth days
```

\begin{equation}
k = \frac{\pi A B}{T} = `r round(pi*A*B/T,5)`, (\#eq:k)
\end{equation}

The numerical value of $k$ in \@ref(eq:k) is obtained using the official values for $A$, $B$ and $T$ given below. 

```{r, echo=TRUE, eval=FALSE}
A <- 1.52400 # semimajor axis of Mars in AU
B <- 1.51740 # semiminor axis of Mars in AU
T <- 686.980 # orbital period of Mars in Earth days
```

Note that the value $k_0$ obtained from the linear regression is remarkably close to the theoretical value of $k$ obtained from Kepler's second law. 



# Conclusions

Fitting models to data is fundamentally important to modern data science, and we hope that these activities designed to be used at lower-level undergraduate courses, can help students build mathematical intuition and computing skills, before they tackle more advanced topics in data science. 

For modern data science applications, using big, complex data, we invite the reader to explore further the `tidyverse` \cite{wickham2021b} collection of packages, developed by RStudio, for doing data analysis, visualizations, modeling and machine learning, using tidyverse principles. For a deeper dive into modern data science, we encourage the reader to explore the freely available online books, *Data Science: A First Introduction* \cite{timbers2022}, *Modern Data Science with R* \cite{baumer2021}, and *R for Data Science* \cite{wickham2017}. 


\small




